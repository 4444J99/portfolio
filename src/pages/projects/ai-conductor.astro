---
import Layout from '../../layouts/Layout.astro';
import Header from '../../components/Header.astro';
import Footer from '../../components/Footer.astro';
import ProjectDetail from '../../components/ProjectDetail.astro';
import SketchContainer from '../../components/sketches/SketchContainer.astro';
---

<Layout title="AI-Conductor Model — 4444j" description="The methodology for human-AI co-creation that produced ~320K words of documentation — AI generates volume, human directs and refines.">
  <Header />
  <main>
    <ProjectDetail
      title="AI-Conductor Model"
      tagline="Human-AI co-creation as artistic practice"
      tags={['AI', 'Process', 'Methodology']}
      repo="https://github.com/organvm-v-logos/public-process"
    >
      <h2>The Model</h2>
      <p>
        Every creative team in 2026 is figuring out how to work with AI. Most approaches are "AI replaces human work" or "human ignores AI." I developed a third option: the <strong>AI-conductor model</strong>, where human acts as conductor — setting direction, maintaining quality, making every structural decision — while AI acts as an instrument capable of producing drafts at speed. This isn't "AI wrote my portfolio." It's a designed practice with explicit roles, quality gates, and attribution.
      </p>

      <h2>How It Works in Practice</h2>
      <p>
        <strong>Human provides:</strong> Strategic direction, structural decisions, quality criteria, voice and tone, factual accuracy review, final approval.
      </p>
      <p>
        <strong>AI provides:</strong> Draft generation at speed, consistent formatting, template compliance, volume production, initial cross-reference checking.
      </p>
      <p>
        A typical 3,000-word README: human writes brief → AI generates draft (~15-20K tokens) → human corrects facts, adjusts positioning → AI revises → human approves. Total: ~50-90K tokens, 30-60 minutes human time.
      </p>

      <SketchContainer
        sketchId="token-stream"
        height="350px"
        mobileHeight="250px"
        ariaLabel="Interactive token stream visualization: river of token rectangles flowing left to right through 4 phases (Context, Generation, Review, Validation). River widens at Generation and narrows at Review — the human bottleneck. Tokens change color through review: gold for verified, dim for flagged. Mouse X zooms into phases. Click tokens in Review to see verification status. Running counter ticks toward 320K."
      />

      <h2>The Token Economy</h2>
      <p>
        Effort is measured in LLM API tokens, not human-hours. The bottleneck isn't generation speed — it's review quality.
      </p>
      <div class="table-wrap">
        <table>
          <thead>
            <tr><th>Task Type</th><th>Token Budget</th><th>Human Time</th></tr>
          </thead>
          <tbody>
            <tr><td>README Rewrite</td><td>~72K tokens</td><td>45-60 min</td></tr>
            <tr><td>README Populate (new)</td><td>~88K tokens</td><td>60-90 min</td></tr>
            <tr><td>Essay (4,000-5,000 words)</td><td>~120K tokens</td><td>90-120 min</td></tr>
            <tr><td>Validation Pass (per repo)</td><td>~15K tokens</td><td>10-15 min</td></tr>
            <tr><td>GitHub Actions Workflow</td><td>~55K tokens</td><td>30-45 min</td></tr>
          </tbody>
        </table>
      </div>
      <p>
        Total system budget: ~6.5 million tokens across three phases. 320,000 words produced.
      </p>

      <h2>What Makes This Different</h2>
      <p>
        <strong>Governance.</strong> Every AI-generated document passes through the same promotion state machine as everything else. Specifications, quality gates, validation checklists. This prevents the most common AI failure: plausible text that doesn't say anything useful.
      </p>
      <p>
        <strong>Attribution.</strong> Every document is transparent about its production method. No pretense that a human typed 320K words — and no pretense that AI produced quality work unsupervised.
      </p>
      <p>
        <strong>Artistic intent.</strong> The conductor metaphor is literal. A conductor doesn't play instruments, but the performance is their artistic vision. The structural decisions — what goes in each document, how documents relate, what to emphasize for which audience — these are human decisions. AI is the orchestra.
      </p>

      <h2>Risks We Monitor</h2>
      <ul>
        <li><strong>Hallucinated code examples</strong> — all samples tested or sourced from actual repos</li>
        <li><strong>Generic boilerplate</strong> — project-specific briefs and human review for voice</li>
        <li><strong>Incorrect cross-references</strong> — automated link checking (1,267 links audited)</li>
        <li><strong>Missing context</strong> — extensive project context in each prompt + human accuracy review</li>
      </ul>

      <h2>Why This Matters</h2>
      <p>
        The eight-organ system is proof that human-AI collaboration produces real output at scale — not blog posts, but governance specifications, technical documentation, and systems architecture. The methodology is reusable. The quality gates are adaptable. The attribution model is honest. For a creative team evaluating how to integrate AI into practice, this is a working model, not a pitch deck.
      </p>

    </ProjectDetail>
  </main>
  <Footer />
</Layout>

<script>
  import '../../components/sketches/sketch-loader';
</script>

<style>
  .table-wrap {
    overflow-x: auto;
    -webkit-overflow-scrolling: touch;
  }
</style>
